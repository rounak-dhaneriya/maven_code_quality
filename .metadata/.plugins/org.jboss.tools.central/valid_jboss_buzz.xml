<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Building jBPM Business Applications with Gradle</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/zqCrBZR9teE/building-jbpm-business-applications.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Tihomir Surdilovic</name></author><id>searchisko:content:id:jbossorg_blog-building_jbpm_business_applications_with_gradle</id><updated>2019-01-04T20:11:42Z</updated><published>2019-01-04T18:50:00Z</published><content type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-F9sqxoorDC8/XC-qQeGItsI/AAAAAAAAhrU/UUGSFx5_ZdQ0cORTxE3tiJB-BL5eEzh5wCLcBGAs/s1600/gradle_logo.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="124" data-original-width="406" height="97" src="https://3.bp.blogspot.com/-F9sqxoorDC8/XC-qQeGItsI/AAAAAAAAhrU/UUGSFx5_ZdQ0cORTxE3tiJB-BL5eEzh5wCLcBGAs/s320/gradle_logo.png" width="320" /&gt;&lt;/a&gt;&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;By default &lt;a href="http://jbpm.org/businessapps/gettingStarted.html"&gt;jBPM Business Applications&lt;/a&gt; generated via &lt;a href="http://start.jbpm.org/"&gt;start.jbpm.org&lt;/a&gt;&amp;nbsp;are build with &lt;a href="https://maven.apache.org/"&gt;Apache Maven&lt;/a&gt;. Your generated apps also include build scripts (for Unix, OSX, and Windows) which you can use out of the box to build all the apps modules, as well as launch your app in normal or dev modes.&lt;br /&gt;&lt;br /&gt;Using Maven is fine however it excludes &lt;a href="https://gradle.org/"&gt;Gradle&lt;/a&gt; users from being able to build and launch jBPM Business Applications using their favorite build tool.&lt;br /&gt;&lt;br /&gt;If you are using Gradle, take a look at &lt;a href="https://github.com/tsurdilo/jbpm-business-apps-gradle"&gt;this GitHub repo&lt;/a&gt; which includes Gradle build files as well as build scripts that call Gradle to build and launch your business application.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-yWsCLfajG84/XC-q2iYFWTI/AAAAAAAAhrk/Wx09icdmrgkwrI81uvrKJcM0Av9aDIzGgCLcBGAs/s1600/Screen%2BShot%2B2019-01-04%2Bat%2B1.49.44%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="902" data-original-width="1600" height="180" src="https://2.bp.blogspot.com/-yWsCLfajG84/XC-q2iYFWTI/AAAAAAAAhrk/Wx09icdmrgkwrI81uvrKJcM0Av9aDIzGgCLcBGAs/s320/Screen%2BShot%2B2019-01-04%2Bat%2B1.49.44%2BPM.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;Follow the documentation there to set up your Gradle build environment for your generated jBPM business app.&lt;br /&gt;&lt;br /&gt;Note that the out-of-the-box Maven build scripts are still the preferred choice when building your app. This is because the limitation of the Gradle scripts not being able to deploy your app on Docker and Openshift. We use the &lt;a href="https://maven.fabric8.io/"&gt;fabric8 plugin&lt;/a&gt;&amp;nbsp;to help us do that and this plugin is not currently available for Gradle unfortunately (you can get more info on that &lt;a href="https://github.com/fabric8io/fabric8-maven-plugin/issues/609"&gt;here&lt;/a&gt;).&lt;br /&gt;&lt;br /&gt;Also to note we are not Gradle experts and it would be &lt;b&gt;really&lt;/b&gt;&amp;nbsp;helpful if our &lt;b&gt;jBPM community&lt;/b&gt; could &lt;b&gt;help&lt;/b&gt; us with making the Gradle build for jBPM Business Applications better. If you are interested please clone&amp;nbsp;&lt;a href="https://github.com/tsurdilo/jbpm-business-apps-gradle"&gt;https://github.com/tsurdilo/jbpm-business-apps-gradle&lt;/a&gt;&amp;nbsp;and submit changes via git pull requests and share it to our community. We would really appreciate that!!&lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/zqCrBZR9teE" height="1" width="1" alt=""/&gt;</content><summary>  By default jBPM Business Applications generated via start.jbpm.org are build with Apache Maven. Your generated apps also include build scripts (for Unix, OSX, and Windows) which you can use out of the box to build all the apps modules, as well as launch your app in normal or dev modes. Using Maven is fine however it excludes Gradle users from being able to build and launch jBPM Business Applicat...</summary><dc:creator>Tihomir Surdilovic</dc:creator><dc:date>2019-01-04T18:50:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2019/01/building-jbpm-business-applications.html</feedburner:origLink></entry><entry><title>Integration of container platform essentials (Part 5)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/f3kYhv5o3cI/" /><category term="Containers" /><category term="Integration" /><category term="Microservices" /><category term="Modern App Dev" /><category term="Red Hat OpenShift Container Platform" /><category term="Agile Integration" /><category term="architecture" /><category term="cloud" /><category term="Cloud Integration Platform" /><category term="containers" /><category term="customer experience" /><category term="DevOps" /><category term="howto" /><category term="microservices" /><category term="Red Hat Customers" /><author><name>Eric D. Schabell</name></author><id>https://developers.redhat.com/blog/?p=550987</id><updated>2019-01-04T17:55:46Z</updated><published>2019-01-04T17:55:46Z</published><content type="html">&lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2018/12/20/integration-of-api-management-details-part-4/" target="_blank" rel="noopener"&gt;Part 4 of this series&lt;/a&gt;, we looked into details that determine how your integration becomes the key to transforming your omnichannel customer experience.&lt;/p&gt; &lt;p&gt;It started with laying out the process of how I&amp;#8217;ve approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Now it&amp;#8217;s time to cover more blueprint details.&lt;/p&gt; &lt;p&gt;This article discusses the core elements in the blueprint (&lt;i&gt;&lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;container&lt;/a&gt; platform and &lt;a href="https://developers.redhat.com/blog/category/microservices/"&gt;microservices&lt;/a&gt;) that&lt;/i&gt; are crucial to the generic architectural overview.&lt;/p&gt; &lt;p&gt;&lt;span id="more-550987"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Architectural details&lt;/h2&gt; &lt;p&gt;As mentioned before, the architectural details covered here are based on real customer integration solutions using open source technologies. The elements presented here are then the &lt;i&gt;generic common architectural elements&lt;/i&gt; that I&amp;#8217;ve identified and collected in a generic architectural blueprint. It&amp;#8217;s my intent to provide a blueprint that provides guidance and not deep technical details.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16.png"&gt;&lt;img class=" aligncenter wp-image-552097 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16-1024x295.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16-1024x295.png" alt="Generic common architectural elements" width="640" height="184" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16-1024x295.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16-300x86.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16-768x221.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.17.16.png 1114w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This section covers the visual representations as presented, but it&amp;#8217;s expected that they&amp;#8217;ll be evolving visually over time. There are many ways to represent each element in this architectural blueprint, but I&amp;#8217;ve chosen icons, text, and colors that I hope are going to make it all easy to absorb. Feel free to post comments at the bottom of this article, or &lt;a href="https://www.schabell.org/p/contact.html" target="_blank" rel="noopener"&gt;contact me directly&lt;/a&gt; with your feedback.&lt;/p&gt; &lt;p&gt;Now let&amp;#8217;s take a look at the details in this architecture and outline the elements uncovered in my research.&lt;/p&gt; &lt;h2&gt;Container platform&lt;/h2&gt; &lt;p&gt;Central to all the research I conducted was the use of a container platform for some if not all of the microservices and applications associated with the omnichannel solution.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16.png"&gt;&lt;img class=" aligncenter wp-image-552447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16-1024x95.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16-1024x95.png" alt="Omnichannel customer experience" width="640" height="59" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16-1024x95.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16-300x28.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16-768x71.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.16.png 1102w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Without a doubt, the flexibility and consistency provided by a container platform enhance the delivery of solutions provided by the development teams. The operations teams became efficient with container deployments, management, and monitoring standardized across multi-cloud infrastructures.&lt;/p&gt; &lt;p&gt;Within the container platform, the first elements are related to the microservices intended to facilitate front-end applications interactions with the rest of the integration services. Specific groups of  (front-end) microservices are used to service the externally deployed applications:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Front-end microservices (providing access to internal integration microservices)&lt;/li&gt; &lt;li&gt;Process facade microservices (providing access to automated integration processes)&lt;/li&gt; &lt;li&gt;Other integration applications (providing access to aggregated microservices or other internal applications)&lt;/li&gt; &lt;li&gt;Single sign-on or SSO plugins, which proliferate for security across the microservices and container platform&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Deeper access to internal microservices are the next details we&amp;#8217;ll examine, touching on &lt;i&gt;integration and data microservices.&lt;/i&gt;&lt;/p&gt; &lt;h2&gt;Core microservices&lt;/h2&gt; &lt;p&gt;This section of the blueprint highlights a few containerized services and the core microservices.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25.png"&gt;&lt;img class=" aligncenter wp-image-552127 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25-1024x167.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25-1024x167.png" alt="Containerized services and the core microservices" width="640" height="104" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25-1024x167.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25-300x49.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25-768x126.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-20-at-14.30.25.png 1095w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The process facade microservices expose core process integration functionality that is part of the depicted &lt;i&gt;process server &lt;/i&gt;elements. Most deployments host two servers for availability and to leverage the container platform&amp;#8217;s load balancing features.&lt;/p&gt; &lt;p&gt;The &lt;i&gt;integration microservices &lt;/i&gt;and &lt;i&gt;integration data microservices&lt;/i&gt; provide access to most anything in the organization. Imagine mainframes, third-party helpdesk desktop applications, third-party cloud platform service integrations, or whatever your imagination can come up with. Data integration can be container-native storage, third-party products, or traditional storage components found in any architecture.&lt;/p&gt; &lt;p&gt;An &lt;i&gt;SSO server &lt;/i&gt;element is shown to complete the story of what&amp;#8217;s backing the connectivity from microservices to the authentication and authorization back-end system(s) in an organization.&lt;/p&gt; &lt;p&gt;The final items shown here are special instances of storage labeled &lt;i&gt;real-time data storage&lt;/i&gt;, which was part of a researched solution that included integration services requiring special performance storage in containers to stream video to external applications. Those are interesting enough to show separately here, although you would expect it in the storage services.&lt;/p&gt; &lt;p&gt;These details are not all-telling, but should give you the guidance you&amp;#8217;d need to get started in your own architectural situations.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next&lt;/h2&gt; &lt;p&gt;This overview covers the container platform elements that make up our architecture blueprint for omnichannel customer experience use case.&lt;/p&gt; &lt;p&gt;An overview of the series on omnichannel customer experience portfolio architecture blueprint can be found here:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/28/integration-is-key-to-customer-experience/"&gt;Part 1: How integration is key to customer experience&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/30/common-architectural-elements-for-modern-integration-architectures/"&gt;Part 2: Common architectural elements for modern integration architectures&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/14/integration-of-external-application-details-part-3/"&gt;Part 3: Integration of external application details&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/20/integration-of-api-management-details-part-4/"&gt;Part 4: Integration of API management details&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 5: Integration of container platform essentials (this article)&lt;/li&gt; &lt;li&gt;Part 6: Details of specific elements (storage services)&lt;/li&gt; &lt;li&gt;Part 7: Application integration details&lt;/li&gt; &lt;li&gt;Part 8: Dissecting several specific application integration architectures&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Catch up on any articles you missed by following one of the links above.&lt;/p&gt; &lt;p&gt;Next in this series, we&amp;#8217;ll be taking a look at the details of specific elements in an architecture for omnichannel customer experience.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#38;linkname=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F04%2Fintegration-of-container-platform-essentials-part-5%2F&amp;#038;title=Integration%20of%20container%20platform%20essentials%20%28Part%205%29" data-a2a-url="https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/" data-a2a-title="Integration of container platform essentials (Part 5)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/"&gt;Integration of container platform essentials (Part 5)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/f3kYhv5o3cI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In Part 4 of this series, we looked into details that determine how your integration becomes the key to transforming your omnichannel customer experience. It started with laying out the process of how I&amp;#8217;ve approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Now it&amp;#8217;s time to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/"&gt;Integration of container platform essentials (Part 5)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">550987</post-id><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-01-04T17:55:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/</feedburner:origLink></entry><entry><title>Leveraging OpenShift or Kubernetes for automated performance tests (part 2)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ClaHA80N0xk/" /><category term="CI/CD" /><category term="Containers" /><category term="Java" /><category term="Kubernetes" /><category term="Microservices" /><category term="Modern App Dev" /><category term="Performance" /><category term="Red Hat OpenShift Container Platform" /><category term="ElasticSearch" /><category term="EnMasse" /><category term="Jaeger" /><category term="JMeter" /><category term="kubernetes" /><category term="OpenTracing" /><category term="performance testing" /><category term="prometheus" /><category term="Red Hat OpenShift" /><category term="test automation" /><author><name>Frédéric Giloux</name></author><id>https://developers.redhat.com/blog/?p=549097</id><updated>2019-01-03T13:00:01Z</updated><published>2019-01-03T13:00:01Z</published><content type="html">&lt;p&gt;This is the second of a series of three blogs based on a session I hold at EMEA Red Hat Tech Exchange. In the &lt;a href="https://developers.redhat.com/blog/2018/11/22/automated-performance-testing-kubernetes-openshift/"&gt;first article&lt;/a&gt;, I presented the rationale and approach for leveraging &lt;a href="https://www.openshift.com"&gt;Red Hat OpenShift&lt;/a&gt; or &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; for automated performance testing, and I gave an overview of the setup.&lt;/p&gt; &lt;p&gt;In this article, we will look at building an observability stack that, beyond the support it provides in production, can be leveraged during performance tests. This will provide insight into how the application performs under load.&lt;/p&gt; &lt;p&gt;An example of what is described in this article is available in my &lt;a href="https://github.com/fgiloux/auto-perf-test/"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-549097"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Overview of the setup&lt;/h2&gt; &lt;p id="PQALPeh"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6.png"&gt;&lt;img class="aligncenter wp-image-533387 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-1024x433.png" alt="Overview" width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-1024x433.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-768x324.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6.png 1250w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id="_application_metrics"&gt;Application metrics&lt;/h2&gt; &lt;h3 id="_prometheus_grafana_installation"&gt;Prometheus and Grafana installation&lt;/h3&gt; &lt;p&gt;Until OpenShift 3.10, Ansible playbooks were available for installing Prometheus and Grafana. They are installed together with the &lt;code&gt;openshift-ansible&lt;/code&gt; package and are available at:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;/usr/share/ansible/openshift-ansible/playbooks/openshift-prometheus&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;/usr/share/ansible/openshift-ansible/playbooks/openshift-grafana&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;With OpenShift 3.11, Red Hat provides &lt;a href="https://docs.openshift.com/container-platform/3.11/install_config/prometheus_cluster_monitoring.html"&gt;an operator&lt;/a&gt; that, besides performing the installation, allows you to manage the lifecycle of Prometheus and Grafana (applying updates, for instance). It is, however, important to note that Red Hat supports only the operator and associated Prometheus and Grafana for monitoring the cluster at this point in time. Nothing prevents us, however, from leveraging the operator for installing separate instances if we are comfortable with managing them on our own.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/coreos/prometheus-operator"&gt;The Prometheus operator&lt;/a&gt; can also be used for installation on top of upstream Kubernetes.&lt;/p&gt; &lt;h3 id="_application_jmx_jolokia_prometheus_endpoints"&gt;Application JMX/Jolokia and Prometheus endpoints&lt;/h3&gt; &lt;p&gt;The &lt;a href="https://github.com/fabric8io-images/s2i/blob/master/java/images/rhel/prometheus-config.yml"&gt;Fabric8 S2I java image&lt;/a&gt;, which is used by Fuse, among others,  handily comes with support for exporting metrics to Prometheus. Among others, it has a Prometheus exporter agent, which is started with the application and exposes metrics to be scraped. The Java process is started with &lt;code&gt;-javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=9779:/opt/prometheus/prometheus-config.yml&lt;/code&gt;, where &lt;a href="https://github.com/fabric8io-images/s2i/blob/master/java/images/rhel/prometheus-config.yml"&gt;prometheus-config.yml&lt;/a&gt; already includes all the Camel metrics. You can use the &lt;a href="https://github.com/openshift/source-to-image"&gt;S2I capabilities&lt;/a&gt; of the image to add your own metrics. More information is available &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_fuse/7.0/html/managing_fuse/prometheus#configuring_prometheus"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Most Java applications use JMX for exposing the JVM, frameworks, and application custom metrics. Like the Fabric8 S2I Java image, any Java application can leverage the &lt;a href="https://github.com/prometheus/jmx_exporter"&gt;JMX exporter agent&lt;/a&gt; to make JMX metrics accessible through Prometheus.&lt;/p&gt; &lt;h3 id="_metrics_scraping"&gt;Metrics scraping&lt;/h3&gt; &lt;p&gt;Once the application has made a Prometheus endpoint available, the next step is to tell Prometheus to collect metrics from it. Therefore, a service needs to be created that exposes the Prometheus port (9779) with special annotations. Here is an example:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Service metadata: annotations: prometheus.io/port: '9779' prometheus.io/scheme: http prometheus.io/scrape: 'true' [...]&lt;/pre&gt; &lt;p&gt;Finally, the Prometheus ConfigMap created by the Ansible playbook during the installation into the &lt;code&gt;openshift-metrics&lt;/code&gt; project needs to be amended with a couple of lines where &lt;code&gt;perftest&lt;/code&gt; is the project namespace where my application is deployed. &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config"&gt;Kubernetes SD configurations&lt;/a&gt; allow retrieving scrape targets from Kubernetes&amp;#8217; REST API and staying synchronized with the cluster state. The &lt;code&gt;endpoints&lt;/code&gt; role discovers targets from listed endpoints of a service. For each endpoint address, one target is discovered per port.&lt;/p&gt; &lt;pre&gt;- job_name: 'myapps-job' kubernetes_sd_configs: - role: endpoints namespaces: names: - perftest&lt;/pre&gt; &lt;p&gt;Using &lt;code&gt;relabel&lt;/code&gt;, we can limit the metrics&amp;#8217; scrape to the service name of our application, &lt;code&gt;camel-amq-fakeapp&lt;/code&gt; here, and the port, which is named &lt;code&gt;prometheus&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;relabel_configs: - source_labels: [__meta_kubernetes_service_name] action: keep regex: camel-amq-fakeapp - source_labels: [__meta_kubernetes_pod_container_port_name] action: keep regex: prometheus&lt;/pre&gt; &lt;h3 id="_dashboards"&gt;Dashboards&lt;/h3&gt; &lt;p&gt;Grafana is the tool usually used for data visualization. The first thing is to configure a data source pointing to our Prometheus installation. The following information needs to be provided:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Name: Self-explanatory; I used &lt;code&gt;DS_PROMETHEUS&lt;/code&gt; in my demo&lt;/li&gt; &lt;li&gt;Type: Prometheus&lt;/li&gt; &lt;li&gt;URL: &lt;code&gt;https://prometheus-openshift-metrics.apps.sandbox.com/&lt;/code&gt; (this is to be populated with the Prometheus route)&lt;/li&gt; &lt;li&gt;Access: Server/proxy (named differently depending on the Grafana version)&lt;/li&gt; &lt;li&gt;Skip TLS Verification (Insecure): If we don&amp;#8217;t have a CA configured&lt;/li&gt; &lt;li&gt;Token (under &amp;#8220;Prometheus settings&amp;#8221;): Set to the result of &lt;code&gt;$ oc serviceaccounts get-token prometheus-reader -n openshift-metrics&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Once the data source has been configured, we can create a dashboard making use of it and displaying the collected metrics. Prometheus scrapes them by default every 30 seconds. &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/observability/grafana/overview.json"&gt;Here&lt;/a&gt; is an example that creates the dashboard below. It can be uploaded with the following steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Click the Grafana icon menu on the top left and select &lt;strong&gt;Dashboards&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;New dashboard&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Import Dashboard&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Upload .json File&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Select the JSON file.&lt;/li&gt; &lt;/ol&gt; &lt;p id="afZXNvT"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf.png"&gt;&lt;img class=" aligncenter wp-image-549177 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf-1024x468.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf-1024x468.png" alt="Example dashboard" width="640" height="293" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf-1024x468.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf-300x137.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c16876f642bf-768x351.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Note that this dashboard also contains JMeter metrics (the two graphs on the top line). They will be covered in the third and last article in this series.&lt;/p&gt; &lt;p&gt;The dashboard is contextual: the name of the pod and the instance need to be selected on the top left. These dropdown lists are automatically populated with the data retrieved from OpenShift.&lt;/p&gt; &lt;p&gt;The nice thing with Grafana dashboards is that you can display in one page multiple graphs originating from various sources and realms. This helps with identifying correlations.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The second line contains metrics exposed by Camel: load, failures, and processing times&lt;/li&gt; &lt;li&gt;The third and fourth lines show the resource consumption: memory, CPU, and garbage collections&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I recommend that you have a look at the queries behind each graph and refer to the &lt;a href="https://prometheus.io/docs/"&gt;Prometheus documentation&lt;/a&gt; if you are not familiar with the concepts, metric types, functions, and operators in use. It may give you ideas for building your own dashboards and may provide a practical introduction to the querying capabilities offered.&lt;/p&gt; &lt;h2 id="_application_performance_management"&gt;Application performance management&lt;/h2&gt; &lt;p&gt;Because this article is about performance tests, application performance management is of high relevance. The demo relies on OpenTracing and Jaeger. The instrumentation is split into several parts:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A collector, which acts as a data sink&lt;/li&gt; &lt;li&gt;An agent in charge of sending application metrics to the sink&lt;/li&gt; &lt;li&gt;A front end for querying data from the sink&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It may also be worth mentioning that enMasse/&lt;a href="https://issues.apache.org/jira/browse/ARTEMIS-2028"&gt;ActiveMQ Artemis&lt;/a&gt; is working on adding OpenTracing support.&lt;/p&gt; &lt;h3 id="_collector"&gt;Collector&lt;/h3&gt; &lt;p&gt;Deploying an in-memory Jaeger collector can be done with a single command. A production installation would require the use of Cassandra or Elasticsearch for data storage. Information is available in the &lt;a href="https://github.com/jaegertracing/jaeger-openshift"&gt;jaeger-openshift repository&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;$ oc process -f https://raw.githubusercontent.com/jaegertracing/jaeger-openshift/master/all-in-one/jaeger-all-in-one-template.yml | oc create -f -&lt;/pre&gt; &lt;h3 id="_agent"&gt;Agent&lt;/h3&gt; &lt;p&gt;The agent can be deployed as a sidecar container. This is handy because this setup will work regardless of the language the application is written in. The library deployed with the application will send traces to the localhost using UDP. Therefore, the following needs to be added to the application deployment configuration under the &lt;code&gt;containers&lt;/code&gt; section:&lt;/p&gt; &lt;pre&gt;- image: jaegertracing/jaeger-agent name: jaeger-agent ports: - containerPort: 5775 protocol: UDP - containerPort: 5778 - containerPort: 6831 protocol: UDP - containerPort: 6832 protocol: UDP args: - '--collector.host-port=jaeger-collector.perftest.svc:14267'&lt;/pre&gt; &lt;p&gt;Using the &lt;code&gt;jaeger-java-client&lt;/code&gt; library, we have added the following to the application &lt;code&gt;pom.xml&lt;/code&gt; file.&lt;/p&gt; &lt;pre&gt;&amp;#60;!-- 0.30 matches the dependency in Camel opentracing starter --&amp;#62; &amp;#60;jaeger.version&amp;#62;0.30.1&amp;#60;/jaeger.version&amp;#62; &amp;#60;!-- Opentracing --&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.apache.camel&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;camel-opentracing-starter&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.jaegertracing&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;jaeger-client&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${jaeger.version}&amp;#60;/version&amp;#62; &amp;#60;/dependency&amp;#62;&lt;/pre&gt; &lt;p&gt;The next step is to tell the application to send traces by annotating the &lt;code&gt;Application&lt;/code&gt; class with &lt;code&gt;@CamelOpenTracing&lt;/code&gt; and the &lt;code&gt;Camel OpenTracing&lt;/code&gt; implementation does the rest. Events (spans) are captured for incoming and outgoing messages being sent to/from Camel. Logs are also sent and can be seen when the consumer span is expanded.&lt;/p&gt; &lt;p&gt;Finally, the agent can be configured through environment variables set within the deployment configuration.&lt;/p&gt; &lt;pre&gt;- name: JAEGER_SERVICE_NAME value: fakeapp - name: JAEGER_SAMPLER_PARAM value: '1.0' - name: JAEGER_PROPAGATION value: 'jaeger,b3'&lt;/pre&gt; &lt;p&gt;The service name identifies the service provided by the application component in the trace. By default, Jaeger will send trace information for one call out of 1,000 to limit the burden put on the application. For validating the setup, we may want to tell Jaeger to do it for every single call as done in the code snippet above. Different formats can be used for trace propagation. Jaeger and b3 are configured here.&lt;/p&gt; &lt;h3 id="_frontend"&gt;The front end&lt;/h3&gt; &lt;p&gt;The Jaeger UI has been installed with the collector and a route has been created for reaching it. It can be used to retrieve and display traces and spans. Here is an example of a span. This also includes JMeter producers and consumers. We will see in the third article of this series how they can be added.&lt;/p&gt; &lt;p id="QOFUcSk"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f.png"&gt;&lt;img class=" aligncenter wp-image-549147 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f-1024x435.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f-1024x435.png" alt="Example span" width="640" height="272" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f-1024x435.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/12/img_5c1682c1ebf5f-768x326.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id="_logs"&gt;Logs&lt;/h2&gt; &lt;p&gt;If applications running inside containers write their logs to the standard output, they are with OpenShift automatically aggregated into Elasticsearch and made available for querying and reporting in Kibana. It is best is to have them written in a structured way to add new querying and reporting capabilities. You can find more information on ways to achieve this in a  &lt;a href="https://developers.redhat.com/blog/2018/01/22/openshift-structured-application-logs/"&gt;previous article&lt;/a&gt; of mine.&lt;/p&gt; &lt;h2 id="_broker_and_external_services"&gt;Broker and external services&lt;/h2&gt; &lt;p&gt;Monitoring of the broker is not covered in the demo available in my GitHub repository. I made, however, the assumption that the broker is not the limiting factor during our performance tests. It is best to make sure that this holds true.&lt;/p&gt; &lt;p&gt;EnMasse can be monitored using Prometheus and Grafana. Instructions are provided &lt;a href="http://enmasse.io/documentation/master/openshift/#monitoring-messaging"&gt;here&lt;/a&gt;. Also, it would make sense to reuse the Prometheus and Grafana instances monitoring the application. It seems that metrics are getting added to the information exposed; see &lt;a href="https://github.com/EnMasseProject/enmasse/tree/master/metrics-api"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="_jmeter"&gt;JMeter&lt;/h2&gt; &lt;p&gt;Regarding JMeter, I made a few assumptions in the first article in this series. We would better to validate that the resources made available to JMeter are not a limiting factor. The good thing with having it running on OpenShift is that it is easy to scale vertically or horizontally.&lt;/p&gt; &lt;p&gt;Although it is not covered in my GitHub repository, it would make sense to monitor JMeter using Prometheus and make sure that the JMeter instances were not overheated during the tests. Because JMeter instances may come and go when the tests are launched and terminated (that’s a good thing for freeing up resources), a Prometheus &lt;a href="https://github.com/prometheus/pushgateway"&gt;pushgateway&lt;/a&gt; may be used for metrics collection.&lt;/p&gt; &lt;h2 id="_time_profiling_and_diagnostics"&gt;Time profiling and diagnostics&lt;/h2&gt; &lt;p&gt;As an addition to application performance management, &lt;a href="https://dzone.com/articles/using-java-flight-recorder-with-openjdk-11-1"&gt;Java Flight Recorder&lt;/a&gt; and &lt;a href="https://wiki.openjdk.java.net/display/jmc/Main"&gt;Java Mission Control&lt;/a&gt; have recently been open sourced, and they may be valuable tools when performance issues or degradation are noticed. On top of the metrics already exposed through JMX, JMC provides the capability to properly analyze the information: objects allocated per thread, time spent per thread, call tree, time spent at each level, and so on.&lt;/p&gt; &lt;p&gt;A demonstration is not covered here but may be a subject for a subsequent article.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Thanks for reading. I hope you found this second article interesting. The third and last article will show how JMeter and Jenkins, both running on OpenShift, can be leveraged to automate and orchestrate our performance tests.&lt;/p&gt; &lt;h2&gt;All articles in this series&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/22/automated-performance-testing-kubernetes-openshift/"&gt;Leveraging OpenShift or Kubernetes for automated performance tests (part 1)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Leveraging OpenShift or Kubernetes for automated performance tests (part 2 &amp;#8211; this article)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F03%2Fleveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2%2F&amp;#038;title=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%202%29" data-a2a-url="https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/" data-a2a-title="Leveraging OpenShift or Kubernetes for automated performance tests (part 2)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/"&gt;Leveraging OpenShift or Kubernetes for automated performance tests (part 2)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ClaHA80N0xk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This is the second of a series of three blogs based on a session I hold at EMEA Red Hat Tech Exchange. In the first article, I presented the rationale and approach for leveraging Red Hat OpenShift or Kubernetes for automated performance testing, and I gave an overview of the setup. In this article, we [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/"&gt;Leveraging OpenShift or Kubernetes for automated performance tests (part 2)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">549097</post-id><dc:creator>Frédéric Giloux</dc:creator><dc:date>2019-01-03T13:00:01Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/</feedburner:origLink></entry><entry><title>Apache Camel 2018 Numbers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/E51q9T4-wfQ/apache-camel-2018-numbers.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-apache_camel_2018_numbers</id><updated>2019-01-03T11:04:20Z</updated><published>2019-01-03T11:04:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Its been &lt;a href="http://www.davsclaus.com/2016/12/apache-camel-2016-numbers.html"&gt;2 years&lt;/a&gt; since I last did a blog post about the Camel numbers.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/--ZyoC_7K4ZE/XC3r8N4YihI/AAAAAAAAB0E/R_zzi68w4KQ9_-_R9h8gq7ighQDXJDahACLcBGAs/s1600/camel-stats.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="555" data-original-width="439" height="320" src="https://4.bp.blogspot.com/--ZyoC_7K4ZE/XC3r8N4YihI/AAAAAAAAB0E/R_zzi68w4KQ9_-_R9h8gq7ighQDXJDahACLcBGAs/s320/camel-stats.jpg" width="253" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;Just to do a quick post on some of the numbers for the Apache Camel project in year 2018.&lt;br /&gt;&lt;br /&gt;Number of releases in 2018: &lt;b&gt;12&lt;/b&gt;&lt;br /&gt;Number of posts on Camel user forum in 2018: &lt;b&gt;1266&lt;/b&gt;&lt;br /&gt;Number of gitter chat users at end of 2018: &lt;b&gt;428&lt;/b&gt;&lt;br /&gt;Number of commits in 2018: &lt;b&gt;3600&lt;/b&gt; (&lt;span style="font-family: Courier New, Courier, monospace;"&gt;git shortlog -ns --since 2018-01-01 --until 2019-01-01 | cut -c1-7 | awk '{ SUM += $1} END { print SUM }'&lt;/span&gt;)&lt;br /&gt;&lt;br /&gt;Total number of JIRA tickets created at end of 2018: &lt;b&gt;13033&lt;/b&gt;&lt;br /&gt;Number of JIRA tickets created in 2018: &lt;b&gt;924&lt;/b&gt;&lt;br /&gt;Number of JIRA tickets resolved in 2018: &lt;b&gt;766&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Stackoverflow number of questions at end of 2018: &lt;b&gt;8375&lt;/b&gt;&lt;br /&gt;Stackoverflow number of watchers at end of 2018: &lt;b&gt;1.8k&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Number of stars on github at end of 2018: &lt;b&gt;2303&lt;/b&gt;&lt;br /&gt;Total number of commits at end of 2018: &lt;b&gt;34431&lt;/b&gt;&lt;br /&gt;Total number of contributors on github at end of 2018: &lt;b&gt;447&lt;/b&gt;&lt;br /&gt;Number of closed pull requests at end of 2018: &lt;b&gt;2674&lt;/b&gt;&lt;br /&gt;Number of closed pull requests in 2018: &lt;b&gt;280&lt;/b&gt; (&lt;span style="font-family: Courier New, Courier, monospace;"&gt;is:pr is:closed merged:&amp;gt;=2018-01-01&lt;/span&gt;)&lt;br /&gt;Number of committers doing commits in 2018: &lt;b&gt;184&lt;/b&gt; (&lt;span style="font-family: Courier New, Courier, monospace;"&gt;git shortlog --since 2018-01-01 --until 2019-01-01 -ns | wc -l&lt;/span&gt;).&lt;br /&gt;&lt;br /&gt;The Apache Software Foundation recently posted a &lt;a href="https://blogs.apache.org/foundation/entry/apache-in-2018-by-the"&gt;summary of the most active projects in 2018&lt;/a&gt; and Apache Camel was ranked 4th by commits.&lt;br /&gt;&lt;br /&gt;You can find more statistics for example at &lt;a href="https://github.com/apache/camel"&gt;GitHub&lt;/a&gt; and &lt;a href="https://www.openhub.net/p/camel"&gt;OpenHub&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Happy New Year and 2019 is going to be a special year for Apache Camel, with &lt;a href="http://www.davsclaus.com/2018/12/work-on-apache-camel-3-has-finally.html"&gt;Camel 3 in the works&lt;/a&gt;.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=wEs7qizHeGw:Z6NpRv-schE:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=wEs7qizHeGw:Z6NpRv-schE:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=wEs7qizHeGw:Z6NpRv-schE:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=wEs7qizHeGw:Z6NpRv-schE:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=wEs7qizHeGw:Z6NpRv-schE:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=wEs7qizHeGw:Z6NpRv-schE:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=wEs7qizHeGw:Z6NpRv-schE:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/wEs7qizHeGw" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/E51q9T4-wfQ" height="1" width="1" alt=""/&gt;</content><summary>Its been 2 years since I last did a blog post about the Camel numbers. Just to do a quick post on some of the numbers for the Apache Camel project in year 2018. Number of releases in 2018: 12 Number of posts on Camel user forum in 2018: 1266 Number of gitter chat users at end of 2018: 428 Number of commits in 2018: 3600 (git shortlog -ns --since 2018-01-01 --until 2019-01-01 | cut -c1-7 | awk '{ S...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2019-01-03T11:04:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/wEs7qizHeGw/apache-camel-2018-numbers.html</feedburner:origLink></entry><entry><title>jBPM Business Apps and Okta Single Sign-on (SSO)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pIg480ayWgw/jbpm-business-apps-and-okta-single-sign.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Tihomir Surdilovic</name></author><id>searchisko:content:id:jbossorg_blog-jbpm_business_apps_and_okta_single_sign_on_sso</id><updated>2019-01-02T18:16:07Z</updated><published>2019-01-02T18:16:00Z</published><content type="html">Wanted to showcase a new &lt;a href="https://start.jbpm.org/"&gt;jBPM Business Applications &lt;/a&gt;demo that includes easy&lt;br /&gt;integration with the &lt;a href="https://www.okta.com/"&gt;Okta&lt;/a&gt; identity management service.&lt;br /&gt;&lt;br /&gt;The demo uses the developer.okta.com setup and the &lt;a href="https://github.com/okta/okta-spring-boot"&gt;Okta Spring boot starter&lt;/a&gt; to quickly set up SSO for our jBPM Business App. It also shows how easy it is to restrict access to certain pages of your jBPM Business Application using the authentication info and identity setup in Okta.&lt;br /&gt;&lt;br /&gt;Demo source code is on &lt;a href="https://github.com/business-applications/sample-okta"&gt;github&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;The demo requires you to make an account on &lt;a href="http://developer.okta.com/"&gt;developer.okta.com&lt;/a&gt; (its free) and create an Okta application and set up two group called "Admin" and "Sales"&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://github.com/business-applications/sample-okta/raw/master/img/oktademo5.png?raw=true" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="459" data-original-width="800" height="228" src="https://github.com/business-applications/sample-okta/raw/master/img/oktademo5.png?raw=true" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Okta group setup&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;Only other configuration is in the your apps application.properties file:&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-4IZPtwbgz2g/XCz7qtmNlfI/AAAAAAAAhq4/WwuK7ZGVBOQuBvjH_4Uq9VSo3PZOLif7gCLcBGAs/s1600/Screen%2BShot%2B2019-01-02%2Bat%2B12.57.47%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="212" data-original-width="1600" height="83" src="https://2.bp.blogspot.com/-4IZPtwbgz2g/XCz7qtmNlfI/AAAAAAAAhq4/WwuK7ZGVBOQuBvjH_4Uq9VSo3PZOLif7gCLcBGAs/s640/Screen%2BShot%2B2019-01-02%2Bat%2B12.57.47%2BPM.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;application.properties setup&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;All of this information you get for free once you create an account and an application on the Okta developer site.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once you have completed this setup and start the Okta demo app, go to localhost:8090 and to authenticate and access your app. Note that since there is no logout feature in the demo app, in order to simulate the logout simply delete your recent browser cookies.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;If you don't create and set up the "Sales" group in Okta for your application there accessing localhost:8090/sales will give you a "403" page:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://github.com/business-applications/sample-okta/raw/master/img/oktademo4.png?raw=true" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="230" data-original-width="800" height="115" src="https://github.com/business-applications/sample-okta/raw/master/img/oktademo4.png?raw=true" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Demo app 403 page&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;Otherwise you will be able to access it:&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-v_JUjDA5USQ/XCz85XtyUTI/AAAAAAAAhrE/nBMSFkjtMe4YirPwakx7XzrV106SZXC9ACLcBGAs/s1600/Screen%2BShot%2B2019-01-02%2Bat%2B1.01.47%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="539" data-original-width="1600" height="133" src="https://2.bp.blogspot.com/-v_JUjDA5USQ/XCz85XtyUTI/AAAAAAAAhrE/nBMSFkjtMe4YirPwakx7XzrV106SZXC9ACLcBGAs/s400/Screen%2BShot%2B2019-01-02%2Bat%2B1.01.47%2BPM.png" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Demo sales page&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;The apps index page is authorized to users that are in the "Admin" group that you have set up in Okta.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here is a youtube video which walks you through the Okta demo and shows how simple it is to set&amp;nbsp;&lt;/div&gt;&lt;div&gt;this all up:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;iframe width="320" height="266" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/luIiXnYxE5I/0.jpg" src="https://www.youtube.com/embed/luIiXnYxE5I?feature=player_embedded" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pIg480ayWgw" height="1" width="1" alt=""/&gt;</content><summary>Wanted to showcase a new jBPM Business Applications demo that includes easy integration with the Okta identity management service. The demo uses the developer.okta.com setup and the Okta Spring boot starter to quickly set up SSO for our jBPM Business App. It also shows how easy it is to restrict access to certain pages of your jBPM Business Application using the authentication info and identity se...</summary><dc:creator>Tihomir Surdilovic</dc:creator><dc:date>2019-01-02T18:16:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2019/01/jbpm-business-apps-and-okta-single-sign.html</feedburner:origLink></entry><entry><title>Performance improvements in OVN: Past and future</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/42MGfEVjluM/" /><category term="Infrastructure" /><category term="OpenStack" /><category term="Red Hat Enterprise Linux" /><category term="Red Hat OpenShift Container Platform" /><category term="RHEL8" /><category term="RHEV" /><category term="network function virtualization" /><category term="networking" /><category term="NFV" /><category term="open virtual network" /><category term="Open vSwitch" /><category term="OVN" /><category term="OVS" /><category term="performance" /><category term="virtual networking" /><author><name>Mark Michelson</name></author><id>https://developers.redhat.com/blog/?p=532687</id><updated>2019-01-02T13:00:56Z</updated><published>2019-01-02T13:00:56Z</published><content type="html">&lt;p&gt;&lt;a href="http://www.openvswitch.org/support/dist-docs/ovn-architecture.7.html"&gt;OVN (Open Virtual Network)&lt;/a&gt; is a subcomponent of &lt;a href="http://www.openvswitch.org/"&gt;Open vSwitch (OVS)&lt;/a&gt;. It allows for the expression of overlay networks by connecting logical routers and logical switches. Cloud providers and cloud management systems have been using OVS for many years as a performant method for creating and managing overlay networks.&lt;/p&gt; &lt;p&gt;Lately, OVN has come into its own because it is being used more in Red Hat products. The result has been an increased amount of scrutiny for real-world scenarios with OVN. This has resulted in new features being added to OVN. More importantly, this has led to tremendous changes to improve performance in OVN.&lt;/p&gt; &lt;p&gt;In this article, I will discuss two game-changing performance improvements that have been added to OVN in the past year, and I will discuss future changes that we may see in the coming year.&lt;/p&gt; &lt;p&gt;&lt;span id="more-532687"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Recent improvements&lt;/h2&gt; &lt;h3&gt;&lt;code&gt;ovn-nbctl&lt;/code&gt; daemonization&lt;/h3&gt; &lt;p&gt;One of our first performance targets was to determine the feasibility of supporting clusters the size of &lt;a href="https://www.openshift.com/products/online/"&gt;OpenShift Online&lt;/a&gt;. Based on some expected numbers, we set up tests where we would build the cluster to the expected size, and then simulate the creation and deletion of pods once at scale to see how OVN performed. Based on our initial testing, we were not very happy with the results. As the scale grew, the time it took to make changes to the cluster took longer and longer.&lt;/p&gt; &lt;p&gt;After isolating components and profiling them, we finally had a working theory on what was causing the problem: &lt;a href="http://www.openvswitch.org/support/dist-docs/ovn-nbctl.8.html"&gt;ovn-nbctl&lt;/a&gt;. &lt;code&gt;ovn-nbctl&lt;/code&gt; is a command-line utility that allows for interaction with the OVN northbound database.  This command is the main mechanism by which &lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt; builds its overlay network. I was able to create a shell script that mimicked the setup from our scale tests but that focused solely on the &lt;code&gt;ovn-nbctl&lt;/code&gt; calls. Here is that script:&lt;/p&gt; &lt;pre&gt;#!/bin/bash # Create router ovn-nbctl lr-add router # Create switches for i in $(seq 1 159); do j=$(printf '%02x' $i) ovn-nbctl ls-add ls$i ovn-nbctl lsp-add ls$i lsp-ro$i ovn-nbctl lrp-add router ro-lsp$i 00:00:00:00:00:$j 10.0.0.$i/16 ovn-nbctl set Logical_Switch_Port lsp-ro$i options:router-port=ro-lsp$i type=router addresses=router done for i in $(seq 1 92); do for j in $(seq 1 159); do k=$(printf '%02x' $i) l=$(printf '%02x' $j) create_addrset=$((($j - 1) % 2)) addrset_index=$((($j - 1) / 2)) ovn-nbctl lsp-add ls$j lsp${j}_10.$i.0.$j ovn-nbctl lsp-set-addresses lsp${j}_10.$i.0.$j "00:00:00:00:$k:$l 10.$i.0.$j" if [ $create_addrset -eq 0 ]; then ovn-nbctl create Address_Set name=${i}_${addrset_index} addresses=10.$i.0.$j 1&amp;#62; /dev/null else ovn-nbctl add Address_Set ${i}_${addrset_index} addresses 10.$i.0.$j fi ovn-nbctl acl-add ls$j to-lport 1000 "outport == \"lsp${j}_10.$i.0.$j\" &amp;#38;&amp;#38; ip4.src == \$${i}_${addrset_index}" allow ovn-nbctl acl-add ls$j to-lport 900 "outport == \"lsp${j}_10.$i.0.$j\"" drop done done &lt;/pre&gt; &lt;p&gt;The first loop in the script creates 159 logical switches and connects all of them to a logical router. The next set of nested loops simulates the operations performed when adding a pod to an OpenShift cluster:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;A switch port is added to one of the switches.&lt;/li&gt; &lt;li&gt;The switch port&amp;#8217;s address is added to an address set. Each address set consists of two addresses. Therefore, alternating runs through the loop will either create a new address set or add the switch port&amp;#8217;s address to the address set created during the previous loop iteration.&lt;/li&gt; &lt;li&gt;ACLs are created for the new port. One ACL allows traffic to the port from other addresses in its address set. The other drops all other traffic.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The loops result in 159 switches with 92 ports, totaling 14,628 logical switch ports. Each iteration of the loop calls &lt;code&gt;ovn-nbctl&lt;/code&gt; five times, meaning there are a total of 73,460 invocations of &lt;code&gt;ovn-nbctl&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When we run the script, this is the result:&lt;/p&gt; &lt;pre&gt;$ time ./scale.sh real 759m27.270s user 500m40.805s sys 36m5.682s &lt;/pre&gt; &lt;p&gt;It&amp;#8217;s hard to draw conclusions from that time alone, but I think it&amp;#8217;s fair to say that taking over 12 hours to complete is not good. So let&amp;#8217;s have a look at how long each iteration of the inner loop takes. Click the image below to enlarge it.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize.png"&gt;&lt;img class=" aligncenter wp-image-536427 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize-300x155.png" alt="How long iteration of the inner loop takes" width="300" height="155" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize-300x155.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize-768x398.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_resize.png 1020w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;As you can see in the graph, as the test continues, the amount of time it takes to complete a loop iteration increases. Towards the end, an iteration takes over seven seconds to complete! Why is this?&lt;/p&gt; &lt;p&gt;To understand the issue, let&amp;#8217;s start by taking a closer look at how OVSDB clients and servers work. OVSDB clients and servers communicate using JSONRPC. To prevent the need for raw JSONRPC from being embedded within client code, OVS provides a C-based IDL (interface definition language). The IDL has two responsibilities. First, at compile time, the IDL reads the schema for the databases and generates native C code to allow for programs to read and manipulate the database data in a type-safe way. Second, at runtime, the IDL acts as a translator between the C structures and JSONRPC.&lt;/p&gt; &lt;p&gt;A typical OVSDB client starts by determining which database it is interested in, which tables in that database it is interested in, and which columns&amp;#8217; values within those tables it is interested in. The client formulates a request to the server asking for the current values of those databases, tables, and columns. The server responds with the current values encoded as JSON. The client&amp;#8217;s IDL then translates the JSON into native C structures. The client code can now read the contents of the database by examining C structures. If the client wants to make a modification to the database, it can make its own C data and pass it to the IDL for processing. The IDL then converts this to a JSONRPC database transaction to send to the server.&lt;/p&gt; &lt;p&gt;The IDL also aids the database client for messages originating from the server. If the data in the database changes, the server can send an update JSONRPC message to the client. The IDL then uses this JSONRPC to modify the C data with the updated information.&lt;/p&gt; &lt;p&gt;This works well for long-running OVSDB clients. After the initial dump of the current database, interaction between the client and server happens in small chunks. The problem with &lt;code&gt;ovn-nbctl&lt;/code&gt; is that it is a short-lived process. &lt;code&gt;ovn-nbctl&lt;/code&gt; starts up, requests all data from the northbound database, processes that JSON data into C data, and then usually performs a single operation before exiting. Through our profiling, what we found was that the majority of time was spent by &lt;code&gt;ovn-nbctl&lt;/code&gt; processing the initial database dump at startup. This makes sense when you consider the amount of data being processed as the test reaches its conclusion.&lt;/p&gt; &lt;p&gt;The solution we created was to make &lt;code&gt;ovn-nbctl&lt;/code&gt; have the option of being a long-running process. &lt;code&gt;ovn-nbctl&lt;/code&gt; has been outfitted with an option to allow the OVSDB client portion of it to run in the background continuously. Further invocations of &lt;code&gt;ovn-nbctl&lt;/code&gt; pass the command to the daemon process. The daemon process then passes the result of the command back to the CLI. By doing it this way, the OVSDB client only requires a single database dump from the server, followed by gradual updates of the content. &lt;code&gt;ovn-nbctl&lt;/code&gt; processes can run much faster since they no longer require a dump of the entire database every time.&lt;/p&gt; &lt;p&gt;The solution was initially implemented by Jakub Sitnicki of Red Hat and then improved upon by Ben Pfaff of VMware.&lt;/p&gt; &lt;p&gt;The actual mechanism for running &lt;code&gt;ovn-nbctl&lt;/code&gt; as a daemon is simple. You can run the following command:&lt;/p&gt; &lt;pre&gt;$ export OVN_NB_DAEMON=$(ovn-nbctl --pidfile --detach) &lt;/pre&gt; &lt;p&gt;By setting the &lt;code&gt;OVN_NB_DAEMON&lt;/code&gt; variable, any further calls to &lt;code&gt;ovn-nbctl&lt;/code&gt; will connect to the daemon process.&lt;/p&gt; &lt;p&gt;With this improvement in place, we modified the previous script to have the daemonization line at the beginning. Running the modified script results in the following:&lt;/p&gt; &lt;pre&gt;$ time ./scale-daemon-new.sh real 5m9.950s user 1m18.702s sys 1m41.979s &lt;/pre&gt; &lt;p&gt;That is considerably faster! It&amp;#8217;s over 99% faster, in fact. Here is a graph of each loop iteration. Click the graph to enlarge it.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize.png"&gt;&lt;img class=" aligncenter wp-image-536357 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize-300x176.png" alt="Faster iterations times after modifying the script" width="300" height="176" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize-300x176.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize-768x450.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/cluster_creation_daemonized_resize.png 1020w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;That is a lot more flat than we previously saw. There still is a &lt;em&gt;slight&lt;/em&gt; increase over time. That is due to certain &lt;code&gt;ovn-nbctl&lt;/code&gt; commands becoming more complex as the total data size grows. The scale of the growth is much smaller than in the previous run.&lt;br /&gt; &lt;/p&gt; &lt;h3&gt;Port groups&lt;/h3&gt; &lt;p&gt;Another bottleneck seen in OVN testing was a tremendous slowdown when ACLs were heavily used. Here&amp;#8217;s a script that illustrates the issue well:&lt;/p&gt; &lt;pre&gt;#!/bin/bash NUM_PORTS=${1:-100} ADDR_SET="\"10.1.1.1\"" for x in 1 2 3 4 ; do for y in {0..255} ; do ADDR_SET="${ADDR_SET},\"10.0.$x.$y\"" done done ovn-nbctl create Address_Set name=set1 addresses=$ADDR_SET ovn-nbctl list Address_Set ovn-nbctl ls-add ls0 COUNT=0 while test ${COUNT} -lt ${NUM_PORTS} ; do echo "ovn lsp$COUNT" ovn-nbctl --wait=hv lsp-add ls0 lsp${COUNT} ovn-nbctl acl-add ls0 to-lport 1000 "outport == \"lsp${COUNT}\" &amp;#38;&amp;#38; ip4.src == \$set1" allow ovs-vsctl add-port br-int port${COUNT} \ -- set Interface port${COUNT} external_ids:iface-id=lsp${COUNT} COUNT=$[${COUNT} + 1] done &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s discuss what&amp;#8217;s happening in the script. First, an address set called &lt;code&gt;set1&lt;/code&gt; is created that has 1,020 IP addresses in it (10.0.1.0 through 10.0.4.255). We then create a logical switch &lt;code&gt;ls0&lt;/code&gt; and add &lt;code&gt;NUM_PORTS&lt;/code&gt; to it. &lt;code&gt;NUM_PORTS&lt;/code&gt; defaults to 100, but this can be changed to any value by passing an argument to the script. In our testing, we use 1000 for &lt;code&gt;NUM_PORTS&lt;/code&gt;. In addition to creating the port, we also add a new ACL that allows traffic to go to this new port from any of the addresses in our address set. There are two important other lines here as well&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;code&gt;ovn-nbctl lsp-add&lt;/code&gt; command contains &lt;code&gt;--wait=hv&lt;/code&gt;. This means that the command will block until it has been processed by &lt;code&gt;ovn-controller&lt;/code&gt; processes running on all hypervisors. In our case, we are running in the OVS sandbox, so there is only one hypervisor. That means just waiting for a single &lt;code&gt;ovn-controller&lt;/code&gt; to finish.&lt;/li&gt; &lt;li&gt;There is an &lt;code&gt;ovs-vsctl add-port&lt;/code&gt; command to bind the logical switch port to the OVS &lt;code&gt;br-int&lt;/code&gt; bridge. This makes it so that OpenFlow can be generated by &lt;code&gt;ovn-controller&lt;/code&gt; for this particular logical switch port.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This particular script is not far-fetched. The number of addresses in the address set may be larger than a typical deployment, but this pattern is commonly used by deployments when using ACLs. They create ACLs that are mostly identical aside from the logical switch port that the ACL applies to.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s see what happens when we run this script and create 1,000 logical switch ports.&lt;/p&gt; &lt;pre&gt;$ time ./load_net.sh 1000 real 125m16.022s user 2m47.103s sys 0m11.376s &lt;/pre&gt; &lt;p&gt;The script takes over two hours to complete. Like before, it&amp;#8217;s hard to gauge anything based on a time alone. Let&amp;#8217;s look at what happens when we time each iteration in the loop. Click the picture to enlarge it.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize.png"&gt;&lt;img class=" aligncenter wp-image-536327 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize-300x184.png" alt="Time taken for each iteration in the loop" width="300" height="184" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize-300x184.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize-768x470.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_no_port_groups_resize.png 1020w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Like with the &lt;code&gt;ovn-nbctl&lt;/code&gt; issue before, we can see that the time increases steadily as the test goes on. As the network gets more ACLs, it takes longer for the loop to complete. Why is this?&lt;/p&gt; &lt;p&gt;The answer has to do with the way that &lt;code&gt;ovn-controller&lt;/code&gt; generates OpenFlow. Despite the fact that our ACLs reference a 1,020-member address set as a single unit, that does not translate directly into OpenFlow. Instead, the address set has to be expanded into each individual address, and each individual address is evaluated in a separate flow. When we add our first port, &lt;code&gt;ovn-controller&lt;/code&gt; generates OpenFlow similar to the following for our ACL in OpenFlow table 44:&lt;/p&gt; &lt;pre&gt;priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.1 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.2 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.3 actions=resubmit(,45) ... priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.255.255 actions=resubmit(,45) &lt;/pre&gt; &lt;p&gt;As an explanation:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Table 44 is on the logical switch egress pipeline, and it is where flows pertaining to &lt;code&gt;to-lport&lt;/code&gt; ACLs are written.&lt;/li&gt; &lt;li&gt;&lt;code&gt;metadata&lt;/code&gt; is an identifier for the datapath of the packet. In this case, 0x1 refers to our logical switch.&lt;/li&gt; &lt;li&gt;&lt;code&gt;reg15&lt;/code&gt; is an OpenFlow register that stores the output port number. In this case, 0x1 refers to the first logical switch port we have added. The flow checks the output port because our ACL was a &lt;code&gt;to-lport&lt;/code&gt; ACL. If it had been a &lt;code&gt;from-lport&lt;/code&gt; ACL, then we would have checked the input port instead, and we would do it in a different OpenFlow table.&lt;/li&gt; &lt;li&gt;&lt;code&gt;nw_src&lt;/code&gt; is the network layer source address.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;resubmit(,45)&lt;/code&gt; action allows for processing to continue at OpenFlow table 45. The action is &amp;#8220;resubmit&amp;#8221; in this case because our ACL had an &amp;#8220;allow&amp;#8221; action on it. If it had been &amp;#8220;drop,&amp;#8221; then the flow would have &lt;code&gt;actions=drop&lt;/code&gt; instead.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So in this case, we&amp;#8217;ve created 1,020 flows, one for each address in our address set. Now let&amp;#8217;s see what happens when we add our second port:&lt;/p&gt; &lt;pre&gt;priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.1 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x2,nw_src=10.0.1.1 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.2 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x2,nw_src=10.0.1.2 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.3 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x2,nw_src=10.0.1.3 actions=resubmit(,45) ... priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.4.255 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x2,nw_src=10.0.4.255 actions=resubmit(,45) &lt;/pre&gt; &lt;p&gt;We now have added an identical set of flows, except that &lt;code&gt;reg15&lt;/code&gt; matches &lt;code&gt;0x2&lt;/code&gt; instead of &lt;code&gt;0x1&lt;/code&gt;. In other words, we&amp;#8217;ve created another 1,020 flows for the new port we added. You may notice a pattern forming. The number of flows generated in table 44 is approximately the number of ports multiplied by the number of addresses in the address set. Let&amp;#8217;s count the total number of flows in our table after completing the script:&lt;/p&gt; &lt;pre&gt;$ ovs-ofctl dump-flows br-int | wc -l 1033699 $ ovs-ofctl dump-flows br-int | grep table=44 | wc -l 1025001 &lt;/pre&gt; &lt;p&gt;There are over a million flows, and table 44 accounts for 99% of the total. Bear in mind that in our script, we have &lt;code&gt;--wait=hv&lt;/code&gt; present when adding our logical switch port. This means that we have to wait for &lt;code&gt;ovn-controller&lt;/code&gt; to generate every flow every time that we add a new switch port. Since the table is growing by 1,020+ flows every iteration, it eventually starts to take tens of seconds to add a single port.&lt;/p&gt; &lt;p&gt;The solution to this issue is to try to minimize the number of flows generated. There&amp;#8217;s actually a built-in construct in OVS&amp;#8217;s OpenFlow implementation called a &lt;em&gt;conjunctive match&lt;/em&gt;. A conjunctive match allows for OpenFlow rules that exist in the same table and that have the same resulting action to be combined into a more compact form. If these rules have similar match criteria, then a list of flows pertaining to the first part of the common match criteria can be made, followed by a list of flows pertaining to the second part, and so on until all parts are matched.&lt;/p&gt; &lt;p&gt;Consider the previous set of flows. All of the flows exist in table 44 and have the same action of resubmitting to table 45. All of the flows match first on a port number, and then they all match on a set of IP addresses. What we want is a conjunctive match of two parts. The first part will match on every valid port, and the second part will match on every IP address in our address set. Each time we add a new port, the first part of the conjunctive match will have a new flow added to it, but the second part will remain the same. By doing this, the number of flows in table 44 could be approximated by the number of ports plus the number of addresses in the address set.&lt;/p&gt; &lt;p&gt;To get a conjunctive match generated, several ideas were presented. The one that won out was for the addition of a feature called &lt;em&gt;port groups&lt;/em&gt;. A port group is a simple construct that allows for a number of logical switch ports to be referred to by a single collective name. References to port groups can be made in ACLs in place of where you would normally refer to a single port. Port groups have other nice features, but those lie outside the scope of this particular article.&lt;/p&gt; &lt;p&gt;Port groups were initially implemented by Han Zhou of eBay, but loads of other contributors have fleshed out the feature and improved it since.&lt;/p&gt; &lt;p&gt;Now let&amp;#8217;s rewrite the script using port groups. The major difference will be that instead of defining new ACLs for every port we add, we will define a single ACL that refers to a port group. As we create new logical switch ports, we will add the port to the port group. Having all ports and IP addresses expressed in a single ACL should allow for the conjunctive match to be created. Here is the resulting script:&lt;/p&gt; &lt;pre&gt;#!/bin/bash NUM_PORTS=${1:-100} ADDR_SET="\"10.1.1.1\"" for x in 1 2 3 4 ; do for y in {0..255} ; do ADDR_SET="${ADDR_SET},\"10.0.$x.$y\"" done done ovn-nbctl create Address_Set name=set1 addresses=$ADDR_SET ovn-nbctl list Address_Set ovn-nbctl ls-add ls0 ovn-nbctl create Port_Group name=pg1 ovn-nbctl acl-add ls0 to-lport 1000 "outport == @pg1 &amp;#38;&amp;#38; ip4.src == \$set1" allow ovn-nbctl acl-list ls0 COUNT=0 while test ${COUNT} -lt ${NUM_PORTS} ; do echo "ovn lsp$COUNT" ovn-nbctl --wait=hv lsp-add ls0 lsp${COUNT} port=$(ovn-nbctl get Logical_Switch_Port lsp${COUNT} _uuid) ovn-nbctl add Port_Group pg1 ports $port ovs-vsctl add-port br-int port${COUNT} \ -- set Interface port${COUNT} external_ids:iface-id=lsp${COUNT} COUNT=$[${COUNT} + 1] done &lt;/pre&gt; &lt;p&gt;As you can see, the construction is mostly similar. Notice that we refer to port group &lt;code&gt;pg1&lt;/code&gt; using the &lt;code&gt;@&lt;/code&gt; sign when defining our ACL. This lets OVN know that we are referring to a port group and not a single port in our ACL. Let&amp;#8217;s see what happens when we run this script and create 1,000 logical switch ports.&lt;/p&gt; &lt;pre&gt;$ time ./load_net_pg.sh 1000 real 6m23.696s user 3m15.920s sys 0m10.849s &lt;/pre&gt; &lt;p&gt;Now the script takes only about 6 minutes to complete. That&amp;#8217;s a 95% improvement! Here is a graph of each iteration of the loop. Click the picture to enlarge it.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize.png"&gt;&lt;img class=" aligncenter wp-image-536337 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize-300x189.png" alt="Graph of each iteration of the loop" width="300" height="189" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize-300x189.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize-768x483.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_port_groups_resize.png 1020w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The time is still increasing on each iteration, but if you look at the scale on the y-axis, you can see the times are much lower. To put it in perspective, these are the two graphs superimposed on each other. Click the picture to enlarge it.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize.png"&gt;&lt;img class=" aligncenter wp-image-536347 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize-300x196.png" alt="Two graphs superimposed on each other" width="300" height="196" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize-300x196.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize-768x501.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/acl_timing_resize.png 1020w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can see the blue bars starting to appear in the bottom right of the graph if you squint just so&amp;#8230;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s take a look at the flows generated at each step. After adding one switch port, the OpenFlow looks like this:&lt;/p&gt; &lt;pre&gt;priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.1 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.2 actions=resubmit(,45) priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.1.3 actions=resubmit(,45) ... priority=2000,ip,metadata=0x1,reg15=0x1,nw_src=10.0.4.255 actions=resubmit(,45) &lt;/pre&gt; &lt;p&gt;So far, it&amp;#8217;s exactly the same as when we didn&amp;#8217;t use port groups. Now let&amp;#8217;s add a second port.&lt;/p&gt; &lt;pre&gt;priority=2000,conj_id=2,ip,metadata=0x1 actions=resubmit(,45) priority=2000,ip,metadata=0x1,nw_src=10.0.1.1 actions=conjunction(2,1/2) priority=2000,ip,metadata=0x1,nw_src=10.0.1.2 actions=conjunction(2,1/2) priority=2000,ip,metadata=0x1,nw_src=10.0.1.3 actions=conjunction(2,1/2) ... priority=2000,ip,metadata=0x1,nw_src=10.0.4.255 actions=conjunction(2,1/2) priority=2000,ip,reg15=0x1,metadata=0x1 actions=conjunction(2,2/2) priority=2000,ip,reg15=0x2,metadata=0x1 actions=conjunction(2,2/2) &lt;/pre&gt; &lt;p&gt;And there&amp;#8217;s the conjunctive match we were after! The top line creates the conjunctive match. The ID of the conjunctive match is 2, and it states that if all requirements of the conjunctive match are met, then the action is to resubmit to table 45. The rest of the lines define the requirements of the conjunctive match with their &lt;code&gt;conjunction&lt;/code&gt; actions. The 2 before the comma indicates they are a requirement for the conjunctive match with ID 2. The numbers after the comma indicate the requirement number and total number of requirements of the conjunctive match. All of the flows that end with &lt;code&gt;1/2&lt;/code&gt; in their conjunction action pertain to the source IP address. All flows with &lt;code&gt;2/2&lt;/code&gt; in their conjunction action pertain to the output logical switch port. The conjunctive match results in the same logical set of actions to take but expresses it in a more compact way.&lt;/p&gt; &lt;p&gt;After loading our network up with 1,000 switch ports, let&amp;#8217;s examine the total number of OpenFlow flows generated.&lt;/p&gt; &lt;pre&gt;$ ovs-ofctl dump-flows br-int | wc -l 9098 $ ovs-ofctl dump-flows br-int | table=44 | wc -l 2027 &lt;/pre&gt; &lt;p&gt;That is three orders of magnitude fewer flows than before. Now table 44 accounts for only 22% of the total flows. This makes a world of difference in the time it takes for &lt;code&gt;ovn-controller&lt;/code&gt; to generate the flows.&lt;/p&gt; &lt;h3&gt;Mixing the optimizations&lt;/h3&gt; &lt;p&gt;One thing you may have noticed in our ACL generation script is that we did not use a daemonized &lt;code&gt;ovn-nbctl&lt;/code&gt;. We discussed in the first section how great an optimization that is, so let&amp;#8217;s see how that makes a difference here.&lt;/p&gt; &lt;pre&gt;$ time ./load_net_pg_daemon.sh real 3m50.670s user 0m20.340s sys 0m8.608s &lt;/pre&gt; &lt;p&gt;Not bad! We got another 40% speedup over the non-daemonized version.&lt;/p&gt; &lt;p&gt;And since we&amp;#8217;re crossing streams here, what happens if we take our script from the &lt;code&gt;ovn-nbctl&lt;/code&gt; daemonization section and use port groups with it? Here are the results:&lt;/p&gt; &lt;pre&gt;$ time ./scale-daemon-new-pg.sh real 3m33.457s user 1m1.614s sys 1m24.891s &lt;/pre&gt; &lt;p&gt;There&amp;#8217;s a 31% speedup, but it&amp;#8217;s not due to the same reasons we saw with conjunctive matches earlier. Since there is no &lt;code&gt;--wait=hv&lt;/code&gt; in the script, we are not waiting for &lt;code&gt;ovn-controller&lt;/code&gt; to generate flows. The big reason for the speedup is because using port groups requires fewer calls to &lt;code&gt;ovn-nbctl&lt;/code&gt; than we previously used.&lt;/p&gt; &lt;h2&gt;Future improvements&lt;/h2&gt; &lt;h3&gt;Incremental processing&lt;/h3&gt; &lt;p&gt;One thing you may have noticed from the port groups section was the fact that &lt;code&gt;ovn-controller&lt;/code&gt; has to generate the entire OpenFlow table every time it reads the contents of the southbound database. &lt;code&gt;ovn-northd&lt;/code&gt; works similarly: it always reads the entire northbound database in order to generate a complete new set of southbound data. Operating this way has some distinct advantages.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The code is easy to reason about.&lt;/li&gt; &lt;li&gt;The code is resilient in the case of temporary connectivity failures.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What overshadows these advantages is that this method is slow, computationally expensive, and it gets worse as the size of the dataset increases. A &lt;em&gt;huge&lt;/em&gt; performance boost can be gained by processing the changes to the database rather than all content in the database.&lt;/p&gt; &lt;p&gt;This is a difficult thing to do in practice. There have been multiple attempts to refactor &lt;code&gt;ovn-controller&lt;/code&gt; to process results incrementally. The most common issue with these implementations is increased difficulty in maintaining the code. A common problem seen throughout all attempts is that C doesn&amp;#8217;t provide the easiest way of implementing an incremental processing engine.&lt;/p&gt; &lt;p&gt;Having examined the problems with past attempts and understanding the best way to move forward, engineers at VMware have started an effort to rewrite portions of OVN in a different language than C. They have created a language called &lt;a href="https://github.com/ryzhyk/differential-datalog"&gt;Differential Datalog&lt;/a&gt;, commonly abbreviated DDlog. DDlog at its core is an incremental database processing engine. This is exactly what is needed in order to get more performant processing. Ben Pfaff sent a good &lt;a href="https://mail.openvswitch.org/pipermail/ovs-discuss/2018-November/047665.html"&gt;e-mail&lt;/a&gt; to the ovs-discuss mailing list with a summary of the project.&lt;/p&gt; &lt;p&gt;So what sort of benefits can we expect from incremental processing? Han Zhou of eBay put together a proof-of-concept C version of incremental processing for &lt;code&gt;ovn-controller&lt;/code&gt;. In tests run by him and me, we found around a 90% reduction in CPU usage by &lt;code&gt;ovn-controller&lt;/code&gt;. We also found about a 90% speedup in &lt;code&gt;ovn-controller&lt;/code&gt;&amp;#8216;s general operation. Unlike the optimizations discussed in the previous sections, this doesn&amp;#8217;t apply to specific use cases, but rather provides an optimization for &lt;em&gt;ALL&lt;/em&gt; operations by &lt;code&gt;ovn-controller&lt;/code&gt;. DDlog&amp;#8217;s experimental results on &lt;code&gt;ovn-northd&lt;/code&gt; shows similar improvements. This &lt;a href="https://ovsorbit.org/episode-58-slides.pdf"&gt;presentation&lt;/a&gt; by Leonid Ryzhyk provides some graphs illustrating the immense speedup seen with DDlog&amp;#8217;s incremental computation over the current C implementation at all cluster sizes.&lt;/p&gt; &lt;p&gt;The conversion to DDlog is a work in progress. The intent is to have the DDlog of &lt;code&gt;ovn-northd&lt;/code&gt; finished and integrated into OVN by the release of version 2.11. Once the implementation drops, we encourage everyone to deploy it and tell us about the performance improvements you see. For those of you who are more hesitant about deploying a rewritten OVN component in your live environments, don&amp;#8217;t worry! The C implementation of &lt;code&gt;ovn-northd&lt;/code&gt; will still be present, and you can choose to continue using it instead. But you&amp;#8217;ll be missing out on the amazing performance improvements of the DDlog implementation.&lt;/p&gt; &lt;h3&gt;Other future improvements&lt;/h3&gt; &lt;p&gt;Incremental processing is the foundation on which all future improvements are based. However, even with incremental processing, there are some future smaller improvements that we can visualize. Here is a brief list of possible improvements.&lt;/p&gt; &lt;h4&gt;Incremental flow processing&lt;/h4&gt; &lt;p&gt;&lt;code&gt;ovn-controller&lt;/code&gt; currently creates a collection of all desired flows that it wants to install in OVS. It also maintains a collection of all flows currently installed in OVS. On each iteration, &lt;code&gt;ovn-controller&lt;/code&gt; must determine the difference between the two collections and then send appropriate modification messages to OVS. With incremental processing in place, it naturally follows that we can incrementally calculate the flows to install as well. When testing Han Zhou&amp;#8217;s C implementation of incremental processing, the comparison between desired and installed flows was the new top user of CPU time.&lt;/p&gt; &lt;h4&gt;Pass incremental changes directly&lt;/h4&gt; &lt;p&gt;Once incremental processing is put in place, &lt;code&gt;ovn-northd&lt;/code&gt; will calculate some change to make to the southbound database and make that change. &lt;code&gt;ovn-controller&lt;/code&gt; will take the southbound database contents, determine what has changed, and act on those incremental changes. If &lt;code&gt;ovn-northd&lt;/code&gt; has already calculated what the changes to the southbound database are, perhaps there could be a way to pass the changes directly between &lt;code&gt;ovn-northd&lt;/code&gt; and &lt;code&gt;ovn-controller&lt;/code&gt;. This could eliminate some repetitive processing in the two daemons. It&amp;#8217;s also possible to save some hard drive space that the southbound database would take up.&lt;/p&gt; &lt;p&gt;Of the possible improvements that could be made, this likely would be the most difficult to get right. This is because multiple &lt;code&gt;ovn-controller&lt;/code&gt; daemons connect to the OVN southbound database. Therefore, trying to calculate a universal delta of changes means that it&amp;#8217;s easy for an &lt;code&gt;ovn-controller&lt;/code&gt; to miss an update.&lt;/p&gt; &lt;p&gt;Even if this cannot be done across the board for all southbound data, perhaps something could be done specifically for the southbound Logical_Flow table. That table tends to grow larger than any other southbound table.&lt;/p&gt; &lt;h4&gt;Better conjunctive match generation&lt;/h4&gt; &lt;p&gt;We touched on how previously, conjunctive matches greatly helped to lessen the number of flows that are installed by &lt;code&gt;ovn-controller&lt;/code&gt;. The expression parser in &lt;code&gt;ovn-controller&lt;/code&gt; has difficulty generating conjunctive matches in situations where it really should be able to. It takes some more complex analysis of the resulting flows than currently exists in &lt;code&gt;ovn-controller&lt;/code&gt;. If the expression parser could be made smarter, there might be some savings that could be made to the number of flows generated.&lt;/p&gt; &lt;h4&gt;Centralize expression parsing&lt;/h4&gt; &lt;p&gt;Currently, &lt;code&gt;ovn-controller&lt;/code&gt; reads through logical flows from the southbound database and parses the expressions in order to generate flows for OVS. While there are some logical flows whose resulting parsed form will differ between hypervisors, most of the parsed expressions will be exactly the same no matter where they are parsed. Perhaps some computing power on the hypervisors could be saved by parsing expressions centrally instead.&lt;/p&gt; &lt;h2&gt;Final thoughts&lt;/h2&gt; &lt;p&gt;OVN development is entering an exciting time. Being able to improve performance on such a grand scale is a great sign that the software is maturing. With the introduction of incremental processing, I believe that control plane performance concerns will completely disappear. The use of OVN will become a natural fit for anyone that wants to use OVS in their environments, adding very little overhead.&lt;/p&gt; &lt;p&gt;I suspect that as word gets out about the performance improvements, adoption of OVN will increase even more. Increased adoption means that in addition to no longer needing to focus on performance, we can expect to see a bevy of new features added to OVN in the near future.&lt;/p&gt; &lt;p&gt;If you are interested in contributing, I strongly encourage you to get involved now. This could be the beginning of a golden age of new OVN features to add.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/tag/ovn/"&gt;Open Virtual Network articles on the Red Hat Developer blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/tag/open-vswitch/"&gt;Open vSwitch articles on the Red Hat Developer blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/08/how-to-create-an-open-virtual-network-distributed-gateway-router/" rel="bookmark"&gt;How to create an Open Virtual Network distributed gateway router&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/07/ip-packet-buffering-in-ovn/" rel="bookmark"&gt;IP packet buffering in OVN&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/09/03/ovn-dynamic-ip-address-management/" rel="bookmark"&gt;Dynamic IP Address Management in Open Virtual Network (OVN): Part One&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/03/network-debugging-with-ebpf/" rel="bookmark"&gt;Network debugging with eBPF (RHEL 8 Beta)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking/" rel="bookmark"&gt;Introduction to Linux interfaces for virtual networking&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/09/19/troubleshooting-fdb-table-wrapping-in-open-vswitch/" rel="bookmark"&gt;Troubleshooting FDB table wrapping in Open vSwitch&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/" rel="bookmark"&gt;Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/" rel="bookmark"&gt;Debugging Memory Issues with Open vSwitch DPDK&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2017/06/06/open-vswitch-overview-of-802-1ad-qinq-support/" rel="bookmark"&gt;Open vSwitch: Overview of 802.1ad (QinQ) Support&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#38;linkname=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F02%2Fperformance-improvements-in-ovn-past-and-future%2F&amp;#038;title=Performance%20improvements%20in%20OVN%3A%20Past%20and%20future" data-a2a-url="https://developers.redhat.com/blog/2019/01/02/performance-improvements-in-ovn-past-and-future/" data-a2a-title="Performance improvements in OVN: Past and future"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/02/performance-improvements-in-ovn-past-and-future/"&gt;Performance improvements in OVN: Past and future&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/42MGfEVjluM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;OVN (Open Virtual Network) is a subcomponent of Open vSwitch (OVS). It allows for the expression of overlay networks by connecting logical routers and logical switches. Cloud providers and cloud management systems have been using OVS for many years as a performant method for creating and managing overlay networks. Lately, OVN has come into its [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/02/performance-improvements-in-ovn-past-and-future/"&gt;Performance improvements in OVN: Past and future&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2019/01/02/performance-improvements-in-ovn-past-and-future/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">532687</post-id><dc:creator>Mark Michelson</dc:creator><dc:date>2019-01-02T13:00:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/02/performance-improvements-in-ovn-past-and-future/</feedburner:origLink></entry><entry><title>Modern Process Integration Tooling Workshop - Lab 2 Create a New Project</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/INub5VeeavU/modern-process-integration-tooling-workshop-lab02.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-modern_process_integration_tooling_workshop_lab_2_create_a_new_project</id><updated>2019-01-02T06:00:03Z</updated><published>2019-01-02T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em; text-align: left;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/3" imageanchor="1" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;" target="_blank"&gt;&lt;img alt="process automation manager workshops" border="0" data-original-height="521" data-original-width="819" height="203" src="https://3.bp.blogspot.com/-H2LUVHDZXiI/XAfW1rJVeHI/AAAAAAAAtWU/z6mG0YikV6sCDhZDIamQo3Wd2ntzRl46wCLcBGAs/s320/Screenshot%2B2018-12-05%2Bat%2B14.45.32.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Click to start workshop&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div style="text-align: left;"&gt;&lt;/div&gt;Recently I've started updating my &lt;a href="https://bpmworkshop.gitlab.io/#/" target="_blank"&gt;free online rules and process automation workshops&lt;/a&gt; that showcase how to get started using modern business logic tooling.&lt;br /&gt;&lt;br /&gt;These updates start with moving from JBoss BPM&amp;nbsp; to Red Hat Decision Manager and from JBoss BPM Suite to Red Hat Process Automation Manager.&lt;br /&gt;&lt;br /&gt;This article highlights the second lab update for Red Hat Process Automation Manager, where you learn to create a new project.&lt;br /&gt;&lt;br /&gt;Let's take a look at the lab shall we?&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Lab 2 - Create a new project&lt;/h3&gt;This lab is the second step on learning to develop a process integration project. It's step by step, how to create a new project from scratch.&lt;br /&gt;&lt;br /&gt;The easiest way is to just &lt;a href="https://bpmworkshop.gitlab.io/rhpam/lab02.html" target="_blank"&gt;jump right into lab 2&lt;/a&gt;:&lt;br /&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allowfullscreen="" frameborder="0" height="380" marginheight="0" marginwidth="0" scrolling="no" src="https://bpmworkshop.gitlab.io/rhpam/lab02.html" style="border-width: 1px; border: 1px solid #ccc; margin-bottom: 5px; max-width: 100%;" width="660"&gt;&lt;/iframe&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;Comments or feedback on any part of the workshop that might not be clear, just reach out.&lt;br /&gt;&lt;br /&gt;Stay tuned for the next lab update, coming soon!&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iEJmJdZ4t1I:DkesNLmbKSs:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iEJmJdZ4t1I:DkesNLmbKSs:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iEJmJdZ4t1I:DkesNLmbKSs:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iEJmJdZ4t1I:DkesNLmbKSs:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iEJmJdZ4t1I:DkesNLmbKSs:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/iEJmJdZ4t1I" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/INub5VeeavU" height="1" width="1" alt=""/&gt;</content><summary>Click to start workshop Recently I've started updating my free online rules and process automation workshops that showcase how to get started using modern business logic tooling. These updates start with moving from JBoss BPM  to Red Hat Decision Manager and from JBoss BPM Suite to Red Hat Process Automation Manager. This article highlights the second lab update for Red Hat Process Automation Mana...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-01-02T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/iEJmJdZ4t1I/modern-process-integration-tooling-workshop-lab02.html</feedburner:origLink></entry><entry><title>2018 in review - Portfolio Architecture and storytelling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/etceKPRg-d0/2018-in-review-portfolio-architecture-and-storytelling.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="BPM Suite" scheme="searchisko:content:tags" /><category term="BRMS" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="General" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="JBossDevStudio" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="Tips&amp;Tricks" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-2018_in_review_portfolio_architecture_and_storytelling</id><updated>2018-12-31T06:00:02Z</updated><published>2018-12-31T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;a href="https://3.bp.blogspot.com/-69AkBod_11o/XBqkNp29uQI/AAAAAAAAtXM/lwLznpEFaL8EX47qJxvlJx_7FjBe4qJnwCLcBGAs/s1600/2018.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="2018 in review" border="0" data-original-height="656" data-original-width="1600" height="131" src="https://3.bp.blogspot.com/-69AkBod_11o/XBqkNp29uQI/AAAAAAAAtXM/lwLznpEFaL8EX47qJxvlJx_7FjBe4qJnwCLcBGAs/s320/2018.png" title="" width="320" /&gt;&lt;/a&gt;Every year ends and every year it's always good to look back on the times we have shared, the trips taken and what's been accomplished.&lt;br /&gt;&lt;br /&gt;This year I transitioned into a new team focused on the entire Portfolio, specifically generating solution architecture blueprints.&lt;br /&gt;&lt;br /&gt;While I continue to function as a Global Technology Evangelist, I've also been tasked with creating &lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-introduction.html" target="_blank"&gt;generic architectural blueprints&lt;/a&gt; of real customer based solutions that make use of the open technology portfolio at Red Hat. Watch for more of this in my publishing, social media, and talks in 2019.&lt;br /&gt;&lt;br /&gt;I am now approaching ten years at Red Hat and &lt;a href="https://www.redhat.com/en/about/press-releases/ibm-acquire-red-hat-completely-changing-cloud-landscape-and-becoming-worlds-1-hybrid-cloud-provider" target="_blank"&gt;we're living in interesting times&lt;/a&gt;. With that in mind, here's my review activities from 2018.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Publishing&lt;/h3&gt;&lt;div&gt;Writing's still a high point in my role at Red Hat, with &lt;a href="http://www.schabell.org/2018/" target="_blank"&gt;55+ articles published on this site&lt;/a&gt;, 18+ articles &lt;a href="http://dzone.com/users/eschabell" target="_blank"&gt;syndicated on DZone&lt;/a&gt;, and 17+ articles featured elsewhere in other channels.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://4.bp.blogspot.com/-kfTesgjhk60/Wv7Bh9n8gaI/AAAAAAAAsqg/-qGG2sV-Q0sLUe5LqAr_Habll-MoqV90gCPcBGAYYCw/s1600/IMG_9982.JPG" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="2018 in reveiw" border="0" data-original-height="1600" data-original-width="900" height="320" src="https://4.bp.blogspot.com/-kfTesgjhk60/Wv7Bh9n8gaI/AAAAAAAAsqg/-qGG2sV-Q0sLUe5LqAr_Habll-MoqV90gCPcBGAYYCw/s320/IMG_9982.JPG" title="" width="180" /&gt;&lt;/a&gt;My book project titled, Effective Business Process Management with JBoss BPM was purchased from Manning by Red Hat.&amp;nbsp; The content has been put in to a book format to be released as &lt;a href="http://bit.ly/effective-jboss-bpm" target="_blank"&gt;a free download through the Red Hat Developers Program&lt;/a&gt;. There were even printed versions signed and given away at Red Hat Summit 2019, but if you missed that you can still contact me for a free copy as long as they last.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;My hobby of writing as a&amp;nbsp;&lt;a href="http://www.redsoxlife.com/search/label/ericschabell" target="_blank"&gt;sports journalist for RedSoxLife.com&lt;/a&gt;&amp;nbsp;continued, but at a much slower this year.&lt;br /&gt;&lt;br /&gt;I only pushed out one article a month on average, but that will again pick up once I finish up the book.&lt;br /&gt;&lt;br /&gt;Finally, I spent a lot of time this year presenting on the softer skills in open source. &lt;a href="https://www.slideshare.net/eschabell/storytelling-how-to-build-and-deliver-a-story" target="_blank"&gt;Storytelling&lt;/a&gt; and how to sessions for jump starting a career in open source touched off a series of trips and conference visits this year. A complex central US tour of customers, a recorded session on a special stage in Croatia and Raleigh were the results.&lt;br /&gt;&lt;br /&gt;Check out this small sample (just 6 minutes):&lt;br /&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/LQ2BYca8u48" width="560"&gt;&lt;/iframe&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;It's nice to reach a stage in my career where it's possible to share experience, tricks, and just simple things that can make others better at what they do. It's the most rewarding part of working in open source, the sharing, mentoring, and collaboration that makes all around you grow.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Coding, demos, workshops&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;This year saw the&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral" target="_blank"&gt;Red Hat Demo Central&lt;/a&gt;&amp;nbsp;repository complete its third year since the &lt;a href="xhttps://github.com/redhatdemocentral/product-demo-template/commits/master" target="_blank"&gt;first commit on April 1, 2016, but move to a new location on GitLab.com&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;It's expanded to over 25 individual projects illustrating containers, cloud operations, deployments, AppDev in the Cloud and more. One of the most exciting and most used project is the&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral/ocp-install-demo" target="_blank"&gt;OpenShift Container Platform installation&lt;/a&gt;, which is easy for anyone to do in just a few minutes.&lt;br /&gt;&lt;br /&gt;I've become rather entranced by the tooling provide to projects hosted on Gitlab and have migrated all my projects and workshops over:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://gitlab.com/eschabell" target="_blank"&gt;My projects&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://appdevcloudworkshop.gitlab.io/#/" target="_blank"&gt;Cloud Agile Integration developer workshop&amp;nbsp;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://bpmworkshop.gitlab.io/#/" target="_blank"&gt;Practical rules and automation workshop&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allowfullscreen="" frameborder="0" height="380" marginheight="0" marginwidth="0" scrolling="no" src="https://bpmworkshop.gitlab.io/index-redhat.html#/" style="border-width: 1px; border: 1px solid #ccc; margin-bottom: 5px; max-width: 100%;" width="660"&gt;&lt;/iframe&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/" target="_blank"&gt;These workshops&lt;/a&gt; are undergoing revisions and updates to add new product innovations so be sure to check them out as they evolve.&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Travel&lt;/h3&gt;&lt;div&gt;Being on the road is part of this job, sometimes it's a lot of fun, sometimes it's not always all that you might think it's cracked up to be.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I have enjoyed all of the trips this year, covering over 143,000 km, 32 cities and 7 countries. The people you meet, the knowledge shared, it's all worth the time spent getting from one destination to another.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://1.bp.blogspot.com/-7gU4x8USlJs/XBqrJ_c7-sI/AAAAAAAAtXY/74SkfhxkZgEvyKwIiYN0Z1ePMBBRkLVawCLcBGAs/s1600/Screenshot%2B2018-12-19%2Bat%2B21.33.26.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img border="0" data-original-height="264" data-original-width="197" src="https://1.bp.blogspot.com/-7gU4x8USlJs/XBqrJ_c7-sI/AAAAAAAAtXY/74SkfhxkZgEvyKwIiYN0Z1ePMBBRkLVawCLcBGAs/s1600/Screenshot%2B2018-12-19%2Bat%2B21.33.26.png" /&gt;&lt;/a&gt;Here are the places I visited to talk about Red Hat technologies or meet with our partners and customers:&lt;/div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Raleigh, NC (4x)&lt;/li&gt;&lt;li&gt;Rome, Italy&lt;/li&gt;&lt;li&gt;Dallas, TX (2x)&lt;/li&gt;&lt;li&gt;Portland, OR&lt;/li&gt;&lt;li&gt;Seattle, WA&lt;/li&gt;&lt;li&gt;San Francisco, CA&lt;/li&gt;&lt;li&gt;London, UK&lt;/li&gt;&lt;li&gt;Split, Croatia&lt;/li&gt;&lt;li&gt;Edinburgh, Scotland&lt;/li&gt;&lt;li&gt;Orlando, FL (2x)&lt;/li&gt;&lt;li&gt;St. Louis, MI&lt;/li&gt;&lt;li&gt;Washington, DC&lt;/li&gt;&lt;li&gt;Munich, Germany&lt;/li&gt;&lt;li&gt;Amsterdam, Netherlands (5x)&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;This year travels were more focused on EMEA and NA, who knows where next year will take me.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Thanks to you all&amp;nbsp;&lt;/h3&gt;I certainly hope you enjoyed what I was able to bring to you in 2018.&lt;br /&gt;&lt;br /&gt;I want to thank you personally for attending any of the webinars, conference sessions, workshops, JUG's, and JBug's were our paths might have crossed or for just taking the time to read a published article.&lt;br /&gt;&lt;br /&gt;2019 kicks off fast and furious with travel to all corners of the world, so stay tuned in here as we explore the amazing things you can achieve with open technologies and hybrid multicloud!&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=NZaR04d5agE:lM3XrrkivQ0:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=NZaR04d5agE:lM3XrrkivQ0:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=NZaR04d5agE:lM3XrrkivQ0:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=NZaR04d5agE:lM3XrrkivQ0:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=NZaR04d5agE:lM3XrrkivQ0:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/NZaR04d5agE" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/etceKPRg-d0" height="1" width="1" alt=""/&gt;</content><summary>Every year ends and every year it's always good to look back on the times we have shared, the trips taken and what's been accomplished. This year I transitioned into a new team focused on the entire Portfolio, specifically generating solution architecture blueprints. While I continue to function as a Global Technology Evangelist, I've also been tasked with creating generic architectural blueprints...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2018-12-31T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/NZaR04d5agE/2018-in-review-portfolio-architecture-and-storytelling.html</feedburner:origLink></entry><entry><title>Integration Key to Customer Experience - Storage Services</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OkJlETzdAes/integration-key-to-customer-experience-storage-services.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="BPM Suite" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-integration_key_to_customer_experience_storage_services</id><updated>2018-12-27T06:00:08Z</updated><published>2018-12-27T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em; text-align: left;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-h6FO-sdoH4A/W-AjgSgf-aI/AAAAAAAAtPw/JFoyKy0JPbU9hj0jggWQqESQc6Ywr0GaQCPcBGAYYCw/s1600/omnichannel-header.png" imageanchor="1" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img alt="omnichannel customer experience" border="0" data-original-height="454" data-original-width="895" height="162" src="https://2.bp.blogspot.com/-h6FO-sdoH4A/W-AjgSgf-aI/AAAAAAAAtPw/JFoyKy0JPbU9hj0jggWQqESQc6Ywr0GaQCPcBGAYYCw/s320/omnichannel-header.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;Part 5 - container platform details&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;In &lt;a href="http://www.schabell.org/2018/12/integraiton-key-to-customer-experience-container-platform.html" target="_blank"&gt;my previous article from this series&lt;/a&gt; we looked in to details that determine how your integration becomes the key to transforming your customer experience.&lt;br /&gt;&lt;br /&gt;It started with laying out the process of how I've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint.&lt;br /&gt;&lt;br /&gt;Now it's time to cover various blueprint details.&lt;br /&gt;&lt;br /&gt;This article covers the final elements in the blueprint &lt;i&gt;storage services, &lt;/i&gt;which are fundamental to the&amp;nbsp;generic architectural overview.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Architectural details&lt;/h3&gt;&lt;div&gt;&lt;div style="text-align: right;"&gt;&lt;/div&gt;&lt;a href="https://4.bp.blogspot.com/-Ga9ccmeyAD4/XBy231PrdEI/AAAAAAAAtZA/WOYNmHXmpcYgE9cbpEmEsiZyDhoMi_aSgCLcBGAs/s1600/Screenshot%2B2018-12-21%2Bat%2B10.47.57.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel customer experience" border="0" data-original-height="177" data-original-width="1110" height="51" src="https://4.bp.blogspot.com/-Ga9ccmeyAD4/XBy231PrdEI/AAAAAAAAtZA/WOYNmHXmpcYgE9cbpEmEsiZyDhoMi_aSgCLcBGAs/s320/Screenshot%2B2018-12-21%2Bat%2B10.47.57.png" title="" width="320" /&gt;&lt;/a&gt;&lt;br /&gt;As mentioned before, the architectural details covered here are base on real customer integration solutions using open source technologies. The elements presented here are then the &lt;i&gt;generic common architectural elements&lt;/i&gt;&amp;nbsp;that I've identified and collected in a generic architectural blueprint. It's my intent to provide a blueprint that provides guidance and not deep technical details.&lt;br /&gt;&lt;br /&gt;This section covers the visual representations as presented, but it's expected that they'll be evolving visually over time. There are many ways to represent each element in this architectural blueprint, but I've chosen icons, text and colours that I hope are going to make it all easy to absorb. Feel free to post comments at the bottom of this post, or &lt;a href="https://www.schabell.org/p/contact.html" target="_blank"&gt;contact me directly&lt;/a&gt; with your feedback.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Now let's take a look at the details in this architecture and outline the elements uncovered in my research.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Storage&lt;/h3&gt;&lt;div&gt;While every organization needs and certainly has chosen one or more the storage services described in this article, for completeness I've presented the most common choices found in my research.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://3.bp.blogspot.com/-ziYQaHItlp8/XBy0mjHrvzI/AAAAAAAAtYw/jYr8jjiGLecO1bODB4a7J1la2_zfd5-0QCLcBGAs/s1600/Screenshot%2B2018-12-21%2Bat%2B10.37.52.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel customer experience" border="0" data-original-height="49" data-original-width="332" height="47" src="https://3.bp.blogspot.com/-ziYQaHItlp8/XBy0mjHrvzI/AAAAAAAAtYw/jYr8jjiGLecO1bODB4a7J1la2_zfd5-0QCLcBGAs/s320/Screenshot%2B2018-12-21%2Bat%2B10.37.52.png" title="" width="320" /&gt;&lt;/a&gt;The basic legacy solution every organization researched had was a &lt;i&gt;virtual block storage (VBS)&lt;/i&gt;&amp;nbsp;solution. It can be in your datacenter, on site in your developer machine, or hosted by almost any cloud provider. It provides the fixed-size raw storage capacity&amp;nbsp;and must have consistent I/O performance with low-latency connectivity.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://1.bp.blogspot.com/-SuDSZwCDqn4/XBy0midBcXI/AAAAAAAAtYs/8287R8TD-Ms7ZacfUWQMvySUcXVNU9L6wCLcBGAs/s1600/Screenshot%2B2018-12-21%2Bat%2B10.38.10.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel customer experience" border="0" data-original-height="47" data-original-width="333" height="45" src="https://1.bp.blogspot.com/-SuDSZwCDqn4/XBy0midBcXI/AAAAAAAAtYs/8287R8TD-Ms7ZacfUWQMvySUcXVNU9L6wCLcBGAs/s320/Screenshot%2B2018-12-21%2Bat%2B10.38.10.png" title="" width="320" /&gt;&lt;/a&gt;When files and data sets become very large, then &lt;i&gt;object-based storage (OBS) &lt;/i&gt;becomes the service of choice. It's available on premise or as services hosted by most cloud providers to ensure you can leverage the persistence of your choice for your specific use case.&lt;br /&gt;&lt;br /&gt;For container-based applications and services, persistence is achieved with &lt;i&gt;container-native storage (CNS)&lt;/i&gt;&amp;nbsp;solutions. As previously mentioned, central to all research conducted was a distinct leaning towards the use of a container platform for applications and microservices.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://1.bp.blogspot.com/-kJxvpXXz2uU/XBy0muzpCwI/AAAAAAAAtYo/_f-paYYJveYr-twDOGld0VTirvzbpdSoACLcBGAs/s1600/Screenshot%2B2018-12-21%2Bat%2B10.38.02.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel customer experience" border="0" data-original-height="45" data-original-width="331" height="43" src="https://1.bp.blogspot.com/-kJxvpXXz2uU/XBy0muzpCwI/AAAAAAAAtYo/_f-paYYJveYr-twDOGld0VTirvzbpdSoACLcBGAs/s320/Screenshot%2B2018-12-21%2Bat%2B10.38.02.png" title="" width="320" /&gt;&lt;/a&gt;The need for storage for these container-based elements leads the organization to search for CNS solutions. It's native to the container platform and delivers the performance and ease of use desired by developers and architects constructing the integration solutions for omnichannel.&lt;br /&gt;&lt;br /&gt;The key to our generic integration with these storage services lies in the previously discussed &lt;i&gt;integration data microservices&lt;/i&gt;&amp;nbsp;that make all forms of storage services available across your architecture. These details are not all-knowing, but should give you the guidance you'd need to get started in your own architectural situations.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;What's next&lt;/h3&gt;&lt;div&gt;This overview covers the container platform elements that make up our architecture blueprint for omnichannel customer experience use case.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;An overview of the series on omnichannel customer experience portfolio architecture blueprint can be found here:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-introduction.html" target="_blank"&gt;An introduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-architectural-elements.html" target="_blank"&gt;Generic common architectural elements&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-external-application-details.html" target="_blank"&gt;External application details&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/12/integration-key-to-customer-experience-api-management-details.html" target="_blank"&gt;API management details&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/12/integraiton-key-to-customer-experience-container-platform.html" target="_blank"&gt;Container platform essentials&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.schabell.org/2018/12/integration-key-to-customer-experience-storage-services.html" target="_blank"&gt;Storage services&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Dissecting several specific cases of integration architecture&lt;/li&gt;&lt;/ol&gt;Catch up on any articles you missed by following one of the links above.&lt;br /&gt;&lt;br /&gt;Next in this series, we start taking a look at specific integration architectures that tie in all the elements we've discussed as part of a specific case in an architecture for omnichannel customer experience.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F36fUl-DcKc:fYaQVS6Utck:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F36fUl-DcKc:fYaQVS6Utck:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F36fUl-DcKc:fYaQVS6Utck:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F36fUl-DcKc:fYaQVS6Utck:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F36fUl-DcKc:fYaQVS6Utck:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/F36fUl-DcKc" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OkJlETzdAes" height="1" width="1" alt=""/&gt;</content><summary>Part 5 - container platform detailsIn my previous article from this series we looked in to details that determine how your integration becomes the key to transforming your customer experience. It started with laying out the process of how I've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Now it's time to cover va...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2018-12-27T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/F36fUl-DcKc/integration-key-to-customer-experience-storage-services.html</feedburner:origLink></entry><entry><title>Camel in Action 2nd edition source code up to date with the Camel 2.23 release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XDWHbmlQTws/camel-in-action-2nd-edition-source-code.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="book" scheme="searchisko:content:tags" /><category term="Camel in Action" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-camel_in_action_2nd_edition_source_code_up_to_date_with_the_camel_2_23_release</id><updated>2018-12-25T10:13:31Z</updated><published>2018-12-25T10:13:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I had some time to work on the &lt;a href="https://github.com/camelinaction/camelinaction2"&gt;source code&lt;/a&gt; for our book during the holidays. This year I have been more busy with other stuff so some of the work needed to keep the source code up to date with newer releases of Camel got a bit neglected.&amp;nbsp;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://www.manning.com/books/camel-in-action-second-edition"&gt;&lt;img border="0" data-original-height="273" data-original-width="477" height="183" src="https://3.bp.blogspot.com/-tFCKQ52y9ds/WnV7x1z_FtI/AAAAAAAABiY/JcHEJnvpHqkbv0XtFNqjT0gGyrowac6BACPcBGAYYCw/s320/cia2-released.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Today I just finished the last bits and pushed to github the changes so we are now fully caught up with the latest Apache Camel 2.23.0 release. You can either use the source code directly from the master branch, or pick one of the &lt;a href="https://github.com/camelinaction/camelinaction2/releases"&gt;releases&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Merry Christmas&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=jbC4CChej20:MLnOth5BPBU:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=jbC4CChej20:MLnOth5BPBU:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=jbC4CChej20:MLnOth5BPBU:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=jbC4CChej20:MLnOth5BPBU:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=jbC4CChej20:MLnOth5BPBU:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=jbC4CChej20:MLnOth5BPBU:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=jbC4CChej20:MLnOth5BPBU:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/jbC4CChej20" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XDWHbmlQTws" height="1" width="1" alt=""/&gt;</content><summary>I had some time to work on the source code for our book during the holidays. This year I have been more busy with other stuff so some of the work needed to keep the source code up to date with newer releases of Camel got a bit neglected.  Today I just finished the last bits and pushed to github the changes so we are now fully caught up with the latest Apache Camel 2.23.0 release. You can either us...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2018-12-25T10:13:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/jbC4CChej20/camel-in-action-2nd-edition-source-code.html</feedburner:origLink></entry></feed>
